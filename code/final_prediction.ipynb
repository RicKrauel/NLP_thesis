{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from HanTa import HanoverTagger as ht\n",
    "from tqdm.auto import tqdm\n",
    "import top2vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim\n",
    "import pickle\n",
    "import mgzip\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyreadr\n",
    "\n",
    "#pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load command\n",
    "with mgzip.open('../data/combined_news_pre.mgzip', 'rb') as handle:\n",
    "    combined_news_pre = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   title                 date  \\\n0      Handel: \"Viele brauchen ja eigentlich nichts m...  2021-11-30 06:07:00   \n1      DGB-Index Gute Arbeit: An den Kosten im Homeof...  2021-11-30 05:50:00   \n2      Coronavirus: RKI registriert erstmals wieder l...  2021-11-30 04:23:00   \n3      Bund-Länder-Runde: Kanzleramtschef fordert Cor...  2021-11-30 02:01:00   \n4      Corona-Impfung für Kinder: Gesundheitsminister...  2021-11-29 19:22:00   \n...                                                  ...                  ...   \n12435              Virus aus Wuhan in Japan festgestellt  2020-01-16 18:17:00   \n12436  Erster Todesfall durch neues, Lungenkrankheit ...  2020-01-12 11:51:00   \n12437  Neues Virus ist wahrscheinlich Ursache von Lun...  2020-01-09 13:38:00   \n12438                         Rätselraten über ein Virus  2020-01-07 17:24:00   \n12439            Inzidenz in Berlin steigt wieder leicht  2022-03-23 08:17:00   \n\n                                           combined_text    newspaper  \\\n0      ZEIT: Herr Weber, Herr Rauschen, Herr Greiner,...         zeit   \n1      Wie gut sind die Arbeitsbedingungen in Deutsch...         zeit   \n2      Die Zahl der Neuinfektionen pro 100.000 \\nEinw...         zeit   \n3      Vor der Bund-Länder-Schalte zur Corona-Krise\\n...         zeit   \n4      Die Gesundheitsministerinnen und -minister der...         zeit   \n...                                                  ...          ...   \n12435  Nach mehr als 40 Infektionen mit einem neuarti...  tagespiegel   \n12436  Erstmals ist ein Patient an der geheimnisvolle...  tagespiegel   \n12437  Die Ausbreitung einer zuvor unbekannten Lungen...  tagespiegel   \n12438  Nachrichten aus der zentralchinesischen Provin...  tagespiegel   \n12439  Die Corona-Inzidenz in Berlin ist wieder leich...  tagespiegel   \n\n                                              text_token  \\\n0      [herr, weber, herr, rauschen, herr, greiner, w...   \n1      [arbeitsbedingung, deutschland, beginn, corona...   \n2      [zahl, neuinfektion, 100000, einwohner, woche,...   \n3      [bundländerschalte, coronakrise, pochen, gesch...   \n4      [gesundheitsministerin, minister, land, corona...   \n...                                                  ...   \n12435  [40, infektion, neuartig, coronavirus, chinesi...   \n12436  [erstmals, patient, geheimnisvoll, lungenkrank...   \n12437  [ausbreitung, zuvor, unbekannt, lungenkrankhei...   \n12438  [nachricht, zentralchinesisch, provinz, hubei,...   \n12439  [coronainzidenz, berlin, steigen, wert, mittwo...   \n\n                                    combined_text_joined  \n0      herr weber herr rauschen herr greiner weihnach...  \n1      arbeitsbedingung deutschland beginn coronapand...  \n2      zahl neuinfektion 100000 einwohner woche angab...  \n3      bundländerschalte coronakrise pochen geschäfts...  \n4      gesundheitsministerin minister land coronaimpf...  \n...                                                  ...  \n12435  40 infektion neuartig coronavirus chinesisch w...  \n12436  erstmals patient geheimnisvoll lungenkrankheit...  \n12437  ausbreitung zuvor unbekannt lungenkrankheit ze...  \n12438  nachricht zentralchinesisch provinz hubei weck...  \n12439  coronainzidenz berlin steigen wert mittwoch 10...  \n\n[28432 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>date</th>\n      <th>combined_text</th>\n      <th>newspaper</th>\n      <th>text_token</th>\n      <th>combined_text_joined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Handel: \"Viele brauchen ja eigentlich nichts m...</td>\n      <td>2021-11-30 06:07:00</td>\n      <td>ZEIT: Herr Weber, Herr Rauschen, Herr Greiner,...</td>\n      <td>zeit</td>\n      <td>[herr, weber, herr, rauschen, herr, greiner, w...</td>\n      <td>herr weber herr rauschen herr greiner weihnach...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DGB-Index Gute Arbeit: An den Kosten im Homeof...</td>\n      <td>2021-11-30 05:50:00</td>\n      <td>Wie gut sind die Arbeitsbedingungen in Deutsch...</td>\n      <td>zeit</td>\n      <td>[arbeitsbedingung, deutschland, beginn, corona...</td>\n      <td>arbeitsbedingung deutschland beginn coronapand...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus: RKI registriert erstmals wieder l...</td>\n      <td>2021-11-30 04:23:00</td>\n      <td>Die Zahl der Neuinfektionen pro 100.000 \\nEinw...</td>\n      <td>zeit</td>\n      <td>[zahl, neuinfektion, 100000, einwohner, woche,...</td>\n      <td>zahl neuinfektion 100000 einwohner woche angab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bund-Länder-Runde: Kanzleramtschef fordert Cor...</td>\n      <td>2021-11-30 02:01:00</td>\n      <td>Vor der Bund-Länder-Schalte zur Corona-Krise\\n...</td>\n      <td>zeit</td>\n      <td>[bundländerschalte, coronakrise, pochen, gesch...</td>\n      <td>bundländerschalte coronakrise pochen geschäfts...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Corona-Impfung für Kinder: Gesundheitsminister...</td>\n      <td>2021-11-29 19:22:00</td>\n      <td>Die Gesundheitsministerinnen und -minister der...</td>\n      <td>zeit</td>\n      <td>[gesundheitsministerin, minister, land, corona...</td>\n      <td>gesundheitsministerin minister land coronaimpf...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12435</th>\n      <td>Virus aus Wuhan in Japan festgestellt</td>\n      <td>2020-01-16 18:17:00</td>\n      <td>Nach mehr als 40 Infektionen mit einem neuarti...</td>\n      <td>tagespiegel</td>\n      <td>[40, infektion, neuartig, coronavirus, chinesi...</td>\n      <td>40 infektion neuartig coronavirus chinesisch w...</td>\n    </tr>\n    <tr>\n      <th>12436</th>\n      <td>Erster Todesfall durch neues, Lungenkrankheit ...</td>\n      <td>2020-01-12 11:51:00</td>\n      <td>Erstmals ist ein Patient an der geheimnisvolle...</td>\n      <td>tagespiegel</td>\n      <td>[erstmals, patient, geheimnisvoll, lungenkrank...</td>\n      <td>erstmals patient geheimnisvoll lungenkrankheit...</td>\n    </tr>\n    <tr>\n      <th>12437</th>\n      <td>Neues Virus ist wahrscheinlich Ursache von Lun...</td>\n      <td>2020-01-09 13:38:00</td>\n      <td>Die Ausbreitung einer zuvor unbekannten Lungen...</td>\n      <td>tagespiegel</td>\n      <td>[ausbreitung, zuvor, unbekannt, lungenkrankhei...</td>\n      <td>ausbreitung zuvor unbekannt lungenkrankheit ze...</td>\n    </tr>\n    <tr>\n      <th>12438</th>\n      <td>Rätselraten über ein Virus</td>\n      <td>2020-01-07 17:24:00</td>\n      <td>Nachrichten aus der zentralchinesischen Provin...</td>\n      <td>tagespiegel</td>\n      <td>[nachricht, zentralchinesisch, provinz, hubei,...</td>\n      <td>nachricht zentralchinesisch provinz hubei weck...</td>\n    </tr>\n    <tr>\n      <th>12439</th>\n      <td>Inzidenz in Berlin steigt wieder leicht</td>\n      <td>2022-03-23 08:17:00</td>\n      <td>Die Corona-Inzidenz in Berlin ist wieder leich...</td>\n      <td>tagespiegel</td>\n      <td>[coronainzidenz, berlin, steigen, wert, mittwo...</td>\n      <td>coronainzidenz berlin steigen wert mittwoch 10...</td>\n    </tr>\n  </tbody>\n</table>\n<p>28432 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_news_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Average sentence length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def avg_sent_len(input):\n",
    "    sent_tokenize_list = sent_tokenize(input)\n",
    "    return sum(len(x.split()) for x in sent_tokenize_list) / len(sent_tokenize_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def avg_sent(input):\n",
    "    sent_tokenize_list = sent_tokenize(input)\n",
    "    return len(sent_tokenize_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/28432 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09aaf4cb9d924519a6dbda2bc05191ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_news_pre['avg_length_sent'] = combined_news_pre['combined_text'].progress_apply(avg_sent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/28432 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aa292a8188f4d85802f2364bad8c492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_news_pre['avg_length'] = combined_news_pre['combined_text'].progress_apply(avg_sent_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Presence of adjectives"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def pos_count(input):\n",
    "    keywords_adj = ['ADJA', 'ADJD', 'ADV']\n",
    "    keywords_noun = ['NN']\n",
    "    count_adj = 0\n",
    "    count_nn = 0\n",
    "    count_total = 0\n",
    "    for word in input:\n",
    "        count_total += 1\n",
    "        tag = tagger.analyze(word)[1]\n",
    "        if tag in keywords_adj:\n",
    "            count_adj += 1\n",
    "        if tag in keywords_noun:\n",
    "            count_nn += 1\n",
    "    if count_total == 0:\n",
    "        count_total = 1\n",
    "    return count_adj, count_nn, count_adj/count_total, count_nn/count_total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3554), Label(value='0 / 3554'))), …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3714101c2c06454186e3299d972986a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_news_pre['pos_count'] = combined_news_pre['text_token'].parallel_apply(pos_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "combined_news_pre[['count_adj', 'count_nn', 'percent_adj', 'percent_nn']] = pd.DataFrame(combined_news_pre['pos_count'].tolist(), index=combined_news_pre.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "combined_news_pre.drop('pos_count', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mention of scientist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def scientist_count(input):\n",
    "    keywords = ['drosten', 'streeck', 'lauterbach', 'kekulé', 'schmidt-chanasit', 'wodarg']\n",
    "    scientist = []\n",
    "    for word in input:\n",
    "        if word in keywords:\n",
    "            scientist.append(word)\n",
    "    return scientist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_scientists = combined_news_pre['text_token'].apply(scientist_count).str.join('|').str.get_dummies()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "combined_news_pre = pd.concat([combined_news_pre, df_scientists], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create doc2vecs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(combined_news_pre['text_token'])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=40, dm=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "doc_ids = []\n",
    "for doc_id in range(len(combined_news_pre)):\n",
    "    doc_ids.append(list(model.dv[doc_id]))\n",
    "combined_news_pre['docvecs'] = doc_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_8203/1941646934.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_news_pre[[\"vec\" + str(int(x)) for x in np.linspace(start=0, stop=99, num=100)]] = combined_news_pre.docvecs.apply(pd.Series)\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_8203/1941646934.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_news_pre[[\"vec\" + str(int(x)) for x in np.linspace(start=0, stop=99, num=100)]] = combined_news_pre.docvecs.apply(pd.Series)\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_8203/1941646934.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_news_pre[[\"vec\" + str(int(x)) for x in np.linspace(start=0, stop=99, num=100)]] = combined_news_pre.docvecs.apply(pd.Series)\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_8203/1941646934.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_news_pre[[\"vec\" + str(int(x)) for x in np.linspace(start=0, stop=99, num=100)]] = combined_news_pre.docvecs.apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "combined_news_pre[[\"vec\" + str(int(x)) for x in np.linspace(start=0, stop=99, num=100)]] = combined_news_pre.docvecs.apply(pd.Series)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "combined_news_pre.drop('docvecs', inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load topic modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "# load precomputed model (learn_ngram OR learn_ngram_full), full uses original text, other one uses preprocessed texts\n",
    "model = top2vec.Top2Vec.load('../models/topic2vec_learn_ngram.t2v')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "[[105,\n  19,\n  126,\n  44,\n  111,\n  158,\n  265,\n  124,\n  185,\n  213,\n  132,\n  244,\n  161,\n  57,\n  72,\n  59,\n  245,\n  187,\n  148,\n  228,\n  246,\n  109,\n  171,\n  117,\n  137,\n  62,\n  130,\n  173,\n  26,\n  206,\n  192,\n  217,\n  266,\n  135,\n  210,\n  144,\n  67,\n  220,\n  69,\n  46,\n  227,\n  81,\n  190,\n  254,\n  243,\n  83],\n [271,\n  248,\n  48,\n  32,\n  114,\n  128,\n  65,\n  193,\n  208,\n  56,\n  77,\n  212,\n  154,\n  87,\n  31,\n  151,\n  129,\n  14,\n  222,\n  39,\n  103,\n  168,\n  66,\n  252,\n  28,\n  5],\n [202,\n  267,\n  189,\n  269,\n  85,\n  272,\n  209,\n  17,\n  200,\n  257,\n  255,\n  104,\n  95,\n  123,\n  195,\n  249,\n  99,\n  37,\n  116,\n  153,\n  13,\n  34,\n  188,\n  152,\n  175,\n  247,\n  40,\n  15,\n  233,\n  268,\n  42,\n  30],\n [73,\n  164,\n  237,\n  207,\n  184,\n  51,\n  78,\n  122,\n  54,\n  260,\n  12,\n  138,\n  97,\n  18,\n  263,\n  91,\n  90,\n  53,\n  98,\n  25,\n  127,\n  1],\n [218,\n  22,\n  182,\n  236,\n  112,\n  75,\n  234,\n  160,\n  259,\n  251,\n  230,\n  176,\n  139,\n  258,\n  8,\n  199,\n  60,\n  55,\n  93,\n  88,\n  134,\n  147,\n  68],\n [215, 145, 23, 70, 100, 186, 225, 6],\n [9, 45, 35, 41, 71, 3],\n [86, 131, 156, 232, 7],\n [140, 108, 163, 205, 113, 16, 118, 261, 231, 146, 10],\n [120,\n  183,\n  221,\n  211,\n  43,\n  141,\n  226,\n  82,\n  178,\n  181,\n  241,\n  121,\n  133,\n  177,\n  167,\n  201,\n  110,\n  214,\n  143,\n  169],\n [203,\n  101,\n  235,\n  36,\n  170,\n  191,\n  159,\n  172,\n  238,\n  49,\n  24,\n  194,\n  89,\n  92,\n  125,\n  264,\n  253,\n  242,\n  27],\n [216, 157, 115, 84, 107, 38, 96, 270, 94, 196, 155, 174, 223, 106],\n [20, 63, 21, 224, 165, 198, 250, 33, 52, 74, 119, 64],\n [240, 149, 256, 150, 180, 162, 50, 80, 229, 102, 29],\n [197, 76, 239, 47, 179, 61, 142, 0],\n [262, 2],\n [11, 219, 204, 79, 166, 136, 58, 4]]"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hierarchical_topic_reduction(17)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "topic_nums, topic_score, topic_words, word_scores = model.get_documents_topics(list(combined_news_pre.index), reduced=True, num_topics=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "combined_news_pre[['top2vec_0', 'top2vec_1']] = topic_nums"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load sentiment predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# load command\n",
    "with mgzip.open('../data/combined_comments_group.mgzip', 'rb') as handle:\n",
    "    combined_comments_group = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "predict = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "predict = combined_news_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "predict = predict.merge(combined_comments_group[['title', 'lexi_score', 'bert_score', 'vote_score', 'bert_label', 'count']], how = 'left', on = 'title')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "predict.drop(['title','date', 'combined_text', 'text_token', 'combined_text_joined'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "predict[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(predict['newspaper'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "predict.drop('newspaper', inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "       avg_length_sent  avg_length  count_adj  count_nn  percent_adj  \\\n0                  132   12.931818         99       308     0.159420   \n1                   45   17.200000         57       177     0.182692   \n2                   47   14.638298         62       136     0.185075   \n3                   27   17.703704         37       118     0.171296   \n4                   23   17.000000         25        96     0.154321   \n...                ...         ...        ...       ...          ...   \n28446               38   17.315789         39       110     0.170306   \n28447               40   13.325000         46       133     0.183267   \n28448               49   15.693878         50       175     0.145349   \n28451               39   15.769231         46       148     0.159722   \n28453               25    9.560000         17        53     0.165049   \n\n       percent_nn  drosten  kekulé  lauterbach  streeck  ...  top2vec_0  \\\n0        0.495974        0       0           0        0  ...         11   \n1        0.567308        0       0           0        0  ...          1   \n2        0.405970        0       0           0        0  ...         16   \n3        0.546296        0       0           0        0  ...          3   \n4        0.592593        0       0           0        0  ...          6   \n...           ...      ...     ...         ...      ...  ...        ...   \n28446    0.480349        0       0           0        0  ...          1   \n28447    0.529880        0       0           0        0  ...         10   \n28448    0.508721        0       0           0        0  ...          6   \n28451    0.513889        0       0           0        0  ...         14   \n28453    0.514563        0       0           0        0  ...          3   \n\n       top2vec_1  lexi_score  bert_score  vote_score  bert_label   count  \\\n0              7    0.159247   -0.534319    0.192604    negative    16.0   \n1              7    0.210111   -0.144371    0.338854    negative    26.0   \n2             15    0.119507   -0.370915    0.148937     neutral    80.0   \n3             13    0.099042   -0.469456    0.107543    negative    89.0   \n4             15    0.097489   -0.436324    0.097489     neutral    37.0   \n...          ...         ...         ...         ...         ...     ...   \n28446         11    0.129952   -0.992965    0.129952    negative     1.0   \n28447          8    0.021458    0.045299    0.045299     neutral     1.0   \n28448         12    0.130321   -0.059480    0.130321     neutral     2.0   \n28451          3    0.067709   -0.893052    0.067709    negative     1.0   \n28453          9    0.101042   -0.396007    0.122232     neutral  6189.0   \n\n       tagespiegel  welt  zeit  \n0                0     0     1  \n1                0     0     1  \n2                0     0     1  \n3                0     0     1  \n4                0     0     1  \n...            ...   ...   ...  \n28446            1     0     0  \n28447            1     0     0  \n28448            1     0     0  \n28451            1     0     0  \n28453            1     0     0  \n\n[24285 rows x 121 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_length_sent</th>\n      <th>avg_length</th>\n      <th>count_adj</th>\n      <th>count_nn</th>\n      <th>percent_adj</th>\n      <th>percent_nn</th>\n      <th>drosten</th>\n      <th>kekulé</th>\n      <th>lauterbach</th>\n      <th>streeck</th>\n      <th>...</th>\n      <th>top2vec_0</th>\n      <th>top2vec_1</th>\n      <th>lexi_score</th>\n      <th>bert_score</th>\n      <th>vote_score</th>\n      <th>bert_label</th>\n      <th>count</th>\n      <th>tagespiegel</th>\n      <th>welt</th>\n      <th>zeit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>132</td>\n      <td>12.931818</td>\n      <td>99</td>\n      <td>308</td>\n      <td>0.159420</td>\n      <td>0.495974</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>11</td>\n      <td>7</td>\n      <td>0.159247</td>\n      <td>-0.534319</td>\n      <td>0.192604</td>\n      <td>negative</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45</td>\n      <td>17.200000</td>\n      <td>57</td>\n      <td>177</td>\n      <td>0.182692</td>\n      <td>0.567308</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.210111</td>\n      <td>-0.144371</td>\n      <td>0.338854</td>\n      <td>negative</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>14.638298</td>\n      <td>62</td>\n      <td>136</td>\n      <td>0.185075</td>\n      <td>0.405970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>16</td>\n      <td>15</td>\n      <td>0.119507</td>\n      <td>-0.370915</td>\n      <td>0.148937</td>\n      <td>neutral</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>17.703704</td>\n      <td>37</td>\n      <td>118</td>\n      <td>0.171296</td>\n      <td>0.546296</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0.099042</td>\n      <td>-0.469456</td>\n      <td>0.107543</td>\n      <td>negative</td>\n      <td>89.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>17.000000</td>\n      <td>25</td>\n      <td>96</td>\n      <td>0.154321</td>\n      <td>0.592593</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>15</td>\n      <td>0.097489</td>\n      <td>-0.436324</td>\n      <td>0.097489</td>\n      <td>neutral</td>\n      <td>37.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28446</th>\n      <td>38</td>\n      <td>17.315789</td>\n      <td>39</td>\n      <td>110</td>\n      <td>0.170306</td>\n      <td>0.480349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0.129952</td>\n      <td>-0.992965</td>\n      <td>0.129952</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28447</th>\n      <td>40</td>\n      <td>13.325000</td>\n      <td>46</td>\n      <td>133</td>\n      <td>0.183267</td>\n      <td>0.529880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>0.021458</td>\n      <td>0.045299</td>\n      <td>0.045299</td>\n      <td>neutral</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28448</th>\n      <td>49</td>\n      <td>15.693878</td>\n      <td>50</td>\n      <td>175</td>\n      <td>0.145349</td>\n      <td>0.508721</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6</td>\n      <td>12</td>\n      <td>0.130321</td>\n      <td>-0.059480</td>\n      <td>0.130321</td>\n      <td>neutral</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28451</th>\n      <td>39</td>\n      <td>15.769231</td>\n      <td>46</td>\n      <td>148</td>\n      <td>0.159722</td>\n      <td>0.513889</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>14</td>\n      <td>3</td>\n      <td>0.067709</td>\n      <td>-0.893052</td>\n      <td>0.067709</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28453</th>\n      <td>25</td>\n      <td>9.560000</td>\n      <td>17</td>\n      <td>53</td>\n      <td>0.165049</td>\n      <td>0.514563</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0.101042</td>\n      <td>-0.396007</td>\n      <td>0.122232</td>\n      <td>neutral</td>\n      <td>6189.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>24285 rows × 121 columns</p>\n</div>"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[predict['bert_score'].notna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "with mgzip.open(\"../data/predict_raw.mgzip\", 'wb') as f:\n",
    "    pickle.dump(predict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "with mgzip.open(\"../data/predict_na.mgzip\", 'wb') as f:\n",
    "    pickle.dump(predict[predict['bert_score'].notna()], f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "predict.drop(['lexi_score', 'vote_score'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "with mgzip.open(\"../data/predict_bert_topic.mgzip\", 'wb') as f:\n",
    "    pickle.dump(predict[predict['bert_score'].notna()], f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "predict.drop(['top2vec_0', 'top2vec_1'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "with mgzip.open(\"../data/predict_bert_notopic.mgzip\", 'wb') as f:\n",
    "    pickle.dump(predict[predict['bert_score'].notna()], f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load the version we like to explore"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "with mgzip.open('../data/predict_bert_topic.mgzip', 'rb') as handle:\n",
    "    predict = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "X = predict[predict['bert_score'].notna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "y = X['bert_label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "X.drop(['bert_score', 'bert_label'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "       avg_length_sent  avg_length  count_adj  count_nn  percent_adj  \\\n0                  132   12.931818         99       308     0.159420   \n1                   45   17.200000         57       177     0.182692   \n2                   47   14.638298         62       136     0.185075   \n3                   27   17.703704         37       118     0.171296   \n4                   23   17.000000         25        96     0.154321   \n...                ...         ...        ...       ...          ...   \n28446               38   17.315789         39       110     0.170306   \n28447               40   13.325000         46       133     0.183267   \n28448               49   15.693878         50       175     0.145349   \n28451               39   15.769231         46       148     0.159722   \n28453               25    9.560000         17        53     0.165049   \n\n       percent_nn  drosten  kekulé  lauterbach  streeck  ...     vec96  \\\n0        0.495974        0       0           0        0  ...  0.223306   \n1        0.567308        0       0           0        0  ... -1.238253   \n2        0.405970        0       0           0        0  ... -0.529035   \n3        0.546296        0       0           0        0  ... -0.049648   \n4        0.592593        0       0           0        0  ... -0.616699   \n...           ...      ...     ...         ...      ...  ...       ...   \n28446    0.480349        0       0           0        0  ... -0.417176   \n28447    0.529880        0       0           0        0  ... -0.862138   \n28448    0.508721        0       0           0        0  ... -0.164128   \n28451    0.513889        0       0           0        0  ... -1.761315   \n28453    0.514563        0       0           0        0  ...  0.010778   \n\n          vec97     vec98     vec99  top2vec_0  top2vec_1   count  \\\n0      1.547494 -0.364949  0.230211         11          7    16.0   \n1     -0.023410  4.192199 -1.047301          1          7    26.0   \n2      0.767990  1.726258  1.916841         16         15    80.0   \n3      0.052805  2.081748  2.100051          3         13    89.0   \n4     -1.511315  1.762218  1.740974          6         15    37.0   \n...         ...       ...       ...        ...        ...     ...   \n28446  0.415955  0.327358 -0.064108          1         11     1.0   \n28447  0.045821  1.401799 -1.091150         10          8     1.0   \n28448  0.295489  1.617298 -1.044370          6         12     2.0   \n28451 -0.497971 -0.103931 -1.272163         14          3     1.0   \n28453  1.069938  1.716763  0.254776          3          9  6189.0   \n\n       tagespiegel  welt  zeit  \n0                0     0     1  \n1                0     0     1  \n2                0     0     1  \n3                0     0     1  \n4                0     0     1  \n...            ...   ...   ...  \n28446            1     0     0  \n28447            1     0     0  \n28448            1     0     0  \n28451            1     0     0  \n28453            1     0     0  \n\n[24285 rows x 117 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_length_sent</th>\n      <th>avg_length</th>\n      <th>count_adj</th>\n      <th>count_nn</th>\n      <th>percent_adj</th>\n      <th>percent_nn</th>\n      <th>drosten</th>\n      <th>kekulé</th>\n      <th>lauterbach</th>\n      <th>streeck</th>\n      <th>...</th>\n      <th>vec96</th>\n      <th>vec97</th>\n      <th>vec98</th>\n      <th>vec99</th>\n      <th>top2vec_0</th>\n      <th>top2vec_1</th>\n      <th>count</th>\n      <th>tagespiegel</th>\n      <th>welt</th>\n      <th>zeit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>132</td>\n      <td>12.931818</td>\n      <td>99</td>\n      <td>308</td>\n      <td>0.159420</td>\n      <td>0.495974</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.223306</td>\n      <td>1.547494</td>\n      <td>-0.364949</td>\n      <td>0.230211</td>\n      <td>11</td>\n      <td>7</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45</td>\n      <td>17.200000</td>\n      <td>57</td>\n      <td>177</td>\n      <td>0.182692</td>\n      <td>0.567308</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.238253</td>\n      <td>-0.023410</td>\n      <td>4.192199</td>\n      <td>-1.047301</td>\n      <td>1</td>\n      <td>7</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>14.638298</td>\n      <td>62</td>\n      <td>136</td>\n      <td>0.185075</td>\n      <td>0.405970</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.529035</td>\n      <td>0.767990</td>\n      <td>1.726258</td>\n      <td>1.916841</td>\n      <td>16</td>\n      <td>15</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>17.703704</td>\n      <td>37</td>\n      <td>118</td>\n      <td>0.171296</td>\n      <td>0.546296</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.049648</td>\n      <td>0.052805</td>\n      <td>2.081748</td>\n      <td>2.100051</td>\n      <td>3</td>\n      <td>13</td>\n      <td>89.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>17.000000</td>\n      <td>25</td>\n      <td>96</td>\n      <td>0.154321</td>\n      <td>0.592593</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.616699</td>\n      <td>-1.511315</td>\n      <td>1.762218</td>\n      <td>1.740974</td>\n      <td>6</td>\n      <td>15</td>\n      <td>37.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28446</th>\n      <td>38</td>\n      <td>17.315789</td>\n      <td>39</td>\n      <td>110</td>\n      <td>0.170306</td>\n      <td>0.480349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.417176</td>\n      <td>0.415955</td>\n      <td>0.327358</td>\n      <td>-0.064108</td>\n      <td>1</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28447</th>\n      <td>40</td>\n      <td>13.325000</td>\n      <td>46</td>\n      <td>133</td>\n      <td>0.183267</td>\n      <td>0.529880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.862138</td>\n      <td>0.045821</td>\n      <td>1.401799</td>\n      <td>-1.091150</td>\n      <td>10</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28448</th>\n      <td>49</td>\n      <td>15.693878</td>\n      <td>50</td>\n      <td>175</td>\n      <td>0.145349</td>\n      <td>0.508721</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.164128</td>\n      <td>0.295489</td>\n      <td>1.617298</td>\n      <td>-1.044370</td>\n      <td>6</td>\n      <td>12</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28451</th>\n      <td>39</td>\n      <td>15.769231</td>\n      <td>46</td>\n      <td>148</td>\n      <td>0.159722</td>\n      <td>0.513889</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.761315</td>\n      <td>-0.497971</td>\n      <td>-0.103931</td>\n      <td>-1.272163</td>\n      <td>14</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28453</th>\n      <td>25</td>\n      <td>9.560000</td>\n      <td>17</td>\n      <td>53</td>\n      <td>0.165049</td>\n      <td>0.514563</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.010778</td>\n      <td>1.069938</td>\n      <td>1.716763</td>\n      <td>0.254776</td>\n      <td>3</td>\n      <td>9</td>\n      <td>6189.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>24285 rows × 117 columns</p>\n</div>"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "0        negative\n1        negative\n2         neutral\n3        negative\n4         neutral\n           ...   \n28446    negative\n28447     neutral\n28448     neutral\n28451    negative\n28453     neutral\nName: bert_label, Length: 24285, dtype: object"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.046 total time=  21.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.049 total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/NLP_thesis_new/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.054 total time=  21.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.064 total time= 2.8min\n",
      "[CV 1/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.049 total time= 1.6min\n",
      "[CV 3/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.059 total time= 2.8min\n",
      "[CV 1/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=-0.783 total time=19.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.058 total time=  21.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=-0.791 total time=19.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=-0.769 total time=20.0min\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'n_estimators': 600,\n 'min_samples_split': 10,\n 'min_samples_leaf': 4,\n 'max_features': 'sqrt',\n 'max_depth': 90,\n 'bootstrap': False}"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5 , cv = 3, verbose = 3, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "rf_random.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   17.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.07673947859024188"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regr = RandomForestRegressor(verbose=1, n_jobs=-1)\n",
    "regr = RandomForestRegressor(verbose = 1, n_jobs = -1, n_estimators = 600, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth = 90, bootstrap = False)\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 670 out of 670 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 670 out of 670 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6249532127261385"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestClassifier(verbose = 1, n_jobs = -1, n_estimators = 670, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt', max_depth = 89, criterion = 'entropy')\n",
    "regr.fit(X_train,y_train)\n",
    "regr.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}