{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import mgzip\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import pyreadr\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choose file we want to predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with mgzip.open('../data/predict_bert_topic.mgzip', 'rb') as handle:\n",
    "    predict = pickle.load(handle)\n",
    "#predict.to_csv('../data/predict_bert_topic.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/3869162192.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/3869162192.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/3869162192.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/3869162192.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop('newspaper', inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "X = predict\n",
    "X = X.dropna()\n",
    "X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
    "X.drop('newspaper', inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Continuous labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/2893972162.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(['bert_score', 'bert_label'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "y = X['bert_score']\n",
    "X.drop(['bert_score', 'bert_label'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Create baseline value using linear regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.06330454354398718"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17404903048763853\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R2 is 6%, MAE is 0.174"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Try ensemble random forest regressor\n",
    "Grid search for parameter tuning, cross validation: 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 3/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.090 total time=  22.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.076 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/NLP_thesis_new/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.079 total time=  23.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.080 total time= 2.6min\n",
      "[CV 1/3] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.070 total time=  22.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=-0.598 total time=23.7min\n",
      "[CV 2/3] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200;, score=0.077 total time=27.6min\n",
      "[CV 1/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.075 total time= 1.6min\n",
      "[CV 1/3] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=-0.865 total time=38.0min\n",
      "[CV 3/3] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200;, score=0.097 total time=27.4min\n",
      "[CV 2/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.079 total time= 1.6min\n",
      "[CV 3/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400;, score=0.095 total time= 2.9min\n",
      "[CV 3/3] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400;, score=0.097 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=-0.740 total time=75.8min\n",
      "[CV 1/3] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400;, score=0.072 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400;, score=0.078 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=-0.910 total time=74.6min\n",
      "[CV 3/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.099 total time= 1.6min\n",
      "[CV 2/3] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=-0.729 total time=38.8min\n",
      "[CV 1/3] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.069 total time=45.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=-0.595 total time=41.9min\n",
      "[CV 2/3] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.079 total time=44.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=-0.912 total time=21.9min\n",
      "[CV 3/3] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=-0.598 total time=73.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'n_estimators': 600,\n 'min_samples_split': 10,\n 'min_samples_leaf': 4,\n 'max_features': 'sqrt',\n 'max_depth': 90,\n 'bootstrap': False}"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10 , cv = 3, verbose = 3, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "rf_random.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   18.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.09278917149305532"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regr = RandomForestRegressor(verbose=1, n_jobs=-1)\n",
    "regr = RandomForestRegressor(verbose = 1, n_jobs = -1, n_estimators = 600, min_samples_split = 10, min_samples_leaf = 4, max_features = 'sqrt', max_depth = 90, bootstrap = False)\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.16896458088878005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 600 out of 600 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R2 is 9.3%, MAE is 0.169"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Try neural network\n",
    "Rescaling of all features to 0-1 for better compatibility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "regr = MLPRegressor(max_iter=2000, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,), (119,119,62)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05, 0.001],\n",
    "    'learning_rate_init': [0.0001,0.001],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = GridSearchCV(regr, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train_norm, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.056 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.014 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.046 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.047 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.047 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.019 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.066 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.050 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.053 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.014 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.060 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.043 (+/-0.049) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.015 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.053 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.098 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.041 (+/-0.033) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.010 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.029) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.138 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.045 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.016 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.057 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.033 (+/-0.030) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.052 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.022 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.047 (+/-0.043) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.035 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.055 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.022 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.040) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.089 (+/-0.034) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.061 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.020 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.051 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.057 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.065 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.018 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.047 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.063 (+/-0.045) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.061 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.024 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.064 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.062 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.060 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.019 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.062 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.092 (+/-0.073) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.058 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "-0.004 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.039 (+/-0.076) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.106 (+/-0.103) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.058 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.010 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.052 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.065 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.026 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.060 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.047 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.070 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.030 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.042) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.070 (+/-0.037) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.039 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.010 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.059 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.043 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.012 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.062 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.048 (+/-0.023) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.049 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.018 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.055) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.038 (+/-0.056) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.047 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.026 (+/-0.027) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.066 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.067 (+/-0.052) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.042 (+/-0.024) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.003 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.001 (+/-0.043) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.093 (+/-0.058) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.041 (+/-0.031) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.011 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.054 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.070 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.049 (+/-0.046) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.020 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.049 (+/-0.066) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.046 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.057 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.031 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.063 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.006 (+/-0.032) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.047 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.009 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.042 (+/-0.065) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.001 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.050 (+/-0.004) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.004 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.008 (+/-0.126) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.026 (+/-0.017) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.052 (+/-0.007) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.004 (+/-0.019) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.171 (+/-0.334) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.013 (+/-0.031) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.008 (+/-0.013) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.062 (+/-0.339) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.083 (+/-0.049) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.003 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.036 (+/-0.032) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.074 (+/-0.079) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.039 (+/-0.025) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.010 (+/-0.005) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.041 (+/-0.024) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.030 (+/-0.026) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.062 (+/-0.028) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.021 (+/-0.003) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.053 (+/-0.315) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.017 (+/-0.017) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.060 (+/-0.024) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.028 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.118 (+/-0.471) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.009 (+/-0.032) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.059 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.009 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.072 (+/-0.017) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.017 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.062 (+/-0.019) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.009 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.060 (+/-0.018) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.040 (+/-0.046) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.067 (+/-0.027) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.011 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.073 (+/-0.024) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.016 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.066 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.006 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.072 (+/-0.020) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.088 (+/-0.031) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.064 (+/-0.019) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.006 (+/-0.023) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.066 (+/-0.031) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.072 (+/-0.041) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.053 (+/-0.034) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.022 (+/-0.012) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.058 (+/-0.051) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.030 (+/-0.030) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.071 (+/-0.028) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.022 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.068 (+/-0.036) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.022 (+/-0.014) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.066 (+/-0.033) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.026 (+/-0.003) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.058 (+/-0.041) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.048 (+/-0.042) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.040 (+/-0.008) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.020 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.061) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.015 (+/-0.021) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.049 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.013 (+/-0.035) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.059 (+/-0.009) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.001 (+/-0.010) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.058 (+/-0.037) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.017 (+/-0.021) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.057 (+/-0.042) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.046 (+/-0.048) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.051 (+/-0.025) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.018 (+/-0.017) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.205 (+/-0.420) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.086 (+/-0.017) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.048 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.007 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.061 (+/-0.034) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.087 (+/-0.044) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.041 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.014 (+/-0.030) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.041 (+/-0.017) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.017 (+/-0.019) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.056 (+/-0.049) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.016 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.261 (+/-0.422) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "-0.025 (+/-0.048) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.064 (+/-0.021) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.020 (+/-0.007) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "-0.369 (+/-0.048) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05880228\n",
      "Iteration 2, loss = 0.04845423\n",
      "Iteration 3, loss = 0.04545185\n",
      "Iteration 4, loss = 0.04409507\n",
      "Iteration 5, loss = 0.04328532\n",
      "Iteration 6, loss = 0.04246440\n",
      "Iteration 7, loss = 0.04124994\n",
      "Iteration 8, loss = 0.04100071\n",
      "Iteration 9, loss = 0.04031971\n",
      "Iteration 10, loss = 0.03969308\n",
      "Iteration 11, loss = 0.03953992\n",
      "Iteration 12, loss = 0.03904640\n",
      "Iteration 13, loss = 0.03864370\n",
      "Iteration 14, loss = 0.03834231\n",
      "Iteration 15, loss = 0.03826871\n",
      "Iteration 16, loss = 0.03764258\n",
      "Iteration 17, loss = 0.03731404\n",
      "Iteration 18, loss = 0.03745823\n",
      "Iteration 19, loss = 0.03725181\n",
      "Iteration 20, loss = 0.03685206\n",
      "Iteration 21, loss = 0.03643515\n",
      "Iteration 22, loss = 0.03656196\n",
      "Iteration 23, loss = 0.03620201\n",
      "Iteration 24, loss = 0.03639028\n",
      "Iteration 25, loss = 0.03608182\n",
      "Iteration 26, loss = 0.03584800\n",
      "Iteration 27, loss = 0.03566277\n",
      "Iteration 28, loss = 0.03555200\n",
      "Iteration 29, loss = 0.03529609\n",
      "Iteration 30, loss = 0.03550666\n",
      "Iteration 31, loss = 0.03535698\n",
      "Iteration 32, loss = 0.03510683\n",
      "Iteration 33, loss = 0.03509675\n",
      "Iteration 34, loss = 0.03506746\n",
      "Iteration 35, loss = 0.03489348\n",
      "Iteration 36, loss = 0.03474834\n",
      "Iteration 37, loss = 0.03473943\n",
      "Iteration 38, loss = 0.03467704\n",
      "Iteration 39, loss = 0.03494344\n",
      "Iteration 40, loss = 0.03458133\n",
      "Iteration 41, loss = 0.03446633\n",
      "Iteration 42, loss = 0.03432474\n",
      "Iteration 43, loss = 0.03460750\n",
      "Iteration 44, loss = 0.03429278\n",
      "Iteration 45, loss = 0.03422763\n",
      "Iteration 46, loss = 0.03432184\n",
      "Iteration 47, loss = 0.03421342\n",
      "Iteration 48, loss = 0.03418758\n",
      "Iteration 49, loss = 0.03410336\n",
      "Iteration 50, loss = 0.03381216\n",
      "Iteration 51, loss = 0.03423771\n",
      "Iteration 52, loss = 0.03406955\n",
      "Iteration 53, loss = 0.03378297\n",
      "Iteration 54, loss = 0.03379600\n",
      "Iteration 55, loss = 0.03374359\n",
      "Iteration 56, loss = 0.03436703\n",
      "Iteration 57, loss = 0.03378996\n",
      "Iteration 58, loss = 0.03384009\n",
      "Iteration 59, loss = 0.03371453\n",
      "Iteration 60, loss = 0.03367903\n",
      "Iteration 61, loss = 0.03356475\n",
      "Iteration 62, loss = 0.03344333\n",
      "Iteration 63, loss = 0.03353337\n",
      "Iteration 64, loss = 0.03359465\n",
      "Iteration 65, loss = 0.03350324\n",
      "Iteration 66, loss = 0.03342859\n",
      "Iteration 67, loss = 0.03343322\n",
      "Iteration 68, loss = 0.03340220\n",
      "Iteration 69, loss = 0.03341363\n",
      "Iteration 70, loss = 0.03368368\n",
      "Iteration 71, loss = 0.03327960\n",
      "Iteration 72, loss = 0.03332437\n",
      "Iteration 73, loss = 0.03344072\n",
      "Iteration 74, loss = 0.03342924\n",
      "Iteration 75, loss = 0.03345855\n",
      "Iteration 76, loss = 0.03323925\n",
      "Iteration 77, loss = 0.03329038\n",
      "Iteration 78, loss = 0.03321935\n",
      "Iteration 79, loss = 0.03350886\n",
      "Iteration 80, loss = 0.03341085\n",
      "Iteration 81, loss = 0.03320450\n",
      "Iteration 82, loss = 0.03350603\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.06472387378707056"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MLPRegressor(max_iter=2000, verbose=2, activation='relu', alpha=0.05, hidden_layer_sizes=(50,100,50), learning_rate='constant', solver='adam', learning_rate_init=0.001)\n",
    "regr.fit(X_train_norm, y_train)\n",
    "regr.score(X_test_norm, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1726337614682266\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test_norm)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R2 is 6%, MAE is 0.172"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Categorical labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/526324045.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/526324045.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/526324045.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/526324045.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop('newspaper', inplace=True, axis=1)\n",
      "/var/folders/06/ng7ccz8d4fdfcgp2wp0g434w0000gn/T/ipykernel_69626/526324045.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(['bert_score', 'bert_label'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X = predict\n",
    "X = X.dropna()\n",
    "X[['tagespiegel', 'welt', 'zeit']] = pd.get_dummies(X['newspaper'])\n",
    "X.drop('newspaper', inplace=True, axis=1)\n",
    "y = X['bert_label']\n",
    "X.drop(['bert_score', 'bert_label'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Create baseline value using logistic regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5686298976790617"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LogisticRegressionCV()\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "0.24166732956805345"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, regr.predict(X_test), average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy is 57%, F1 macro is 24.1%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Try ensemble random forest classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "criterion = ['gini', 'entropy']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion': criterion,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10 , cv = 3, verbose = 3, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "rf_random.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, criterion=entropy, max_depth=110, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.651 total time= 3.0min\n",
      "[CV 1/3] END bootstrap=False, criterion=gini, max_depth=60, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1000;, score=0.556 total time=24.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   58.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6488644871474919"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestClassifier(verbose = 1, n_jobs = -1, n_estimators = 200, min_samples_split = 10, min_samples_leaf = 4, max_features = None, max_depth = 80, criterion = 'entropy', bootstrap=True)\n",
    "regr.fit(X_train,y_train)\n",
    "regr.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.43368988575543943"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, regr.predict(X_test), average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy is 64.8%, F1 macro is 43.3%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Try neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "regr = MLPClassifier(verbose = 1, max_iter=3000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,), (119,119,62)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05, 0.001],\n",
    "    'learning_rate_init': [0.0001,0.001],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = GridSearchCV(regr, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train_norm, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.619 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.592 (+/-0.041) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.609 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.634 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.568 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.614 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.577 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.614 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.575 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.603 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.607 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.622 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.025) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.580 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.622 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.579 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.607 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.626 (+/-0.003) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.612 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.626 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.606 (+/-0.006) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.608 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.600 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.620 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.602 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.621 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.619 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.621 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.610 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.022) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.572 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.605 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.593 (+/-0.053) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.603 (+/-0.007) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.596 (+/-0.066) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.608 (+/-0.021) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.577 (+/-0.002) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.596 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.020) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.605 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.016) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.617 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.626 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.628 (+/-0.005) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.575 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.618 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.633 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.572 (+/-0.018) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.587 (+/-0.043) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.624 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.610 (+/-0.032) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.614 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.623 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.599 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.610 (+/-0.021) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.617 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.627 (+/-0.018) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.592 (+/-0.027) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.614 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.616 (+/-0.022) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.588 (+/-0.019) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.596 (+/-0.018) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.626 (+/-0.017) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.604 (+/-0.020) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.023) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.021) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.615 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.603 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.629 (+/-0.011) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.577 (+/-0.017) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.618 (+/-0.010) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.602 (+/-0.015) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.016) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.573 (+/-0.014) for {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.605 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.628 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.632 (+/-0.018) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.603 (+/-0.011) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.628 (+/-0.014) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.614 (+/-0.012) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.608 (+/-0.004) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.629 (+/-0.012) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.017) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.618 (+/-0.007) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.609 (+/-0.012) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.617 (+/-0.036) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.600 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.020) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.627 (+/-0.025) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.597 (+/-0.016) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.633 (+/-0.015) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.634 (+/-0.017) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.608 (+/-0.009) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.612 (+/-0.035) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.635 (+/-0.013) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.608 (+/-0.018) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.608 (+/-0.021) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.621 (+/-0.006) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.018) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.600 (+/-0.024) for {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.609 (+/-0.018) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.626 (+/-0.019) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.019) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.593 (+/-0.026) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.609 (+/-0.018) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.623 (+/-0.015) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.017) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.601 (+/-0.018) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.609 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.622 (+/-0.021) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.632 (+/-0.022) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.594 (+/-0.025) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.611 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.620 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.630 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.594 (+/-0.043) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.599 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.600 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.631 (+/-0.006) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.631 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.630 (+/-0.016) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.615 (+/-0.004) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.600 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.016) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.569 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.612 (+/-0.026) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.604 (+/-0.030) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.633 (+/-0.017) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.581 (+/-0.016) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (119, 119, 62), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.84886440\n",
      "Iteration 2, loss = 0.79892494\n",
      "Iteration 3, loss = 0.79533719\n",
      "Iteration 4, loss = 0.79222650\n",
      "Iteration 5, loss = 0.78895374\n",
      "Iteration 6, loss = 0.78571603\n",
      "Iteration 7, loss = 0.78265068\n",
      "Iteration 8, loss = 0.77980968\n",
      "Iteration 9, loss = 0.77753542\n",
      "Iteration 10, loss = 0.77470230\n",
      "Iteration 11, loss = 0.77236425\n",
      "Iteration 12, loss = 0.77025055\n",
      "Iteration 13, loss = 0.76851908\n",
      "Iteration 14, loss = 0.76667344\n",
      "Iteration 15, loss = 0.76542007\n",
      "Iteration 16, loss = 0.76378636\n",
      "Iteration 17, loss = 0.76258822\n",
      "Iteration 18, loss = 0.76131407\n",
      "Iteration 19, loss = 0.76018297\n",
      "Iteration 20, loss = 0.75916244\n",
      "Iteration 21, loss = 0.75784883\n",
      "Iteration 22, loss = 0.75737909\n",
      "Iteration 23, loss = 0.75652252\n",
      "Iteration 24, loss = 0.75558592\n",
      "Iteration 25, loss = 0.75483001\n",
      "Iteration 26, loss = 0.75392748\n",
      "Iteration 27, loss = 0.75307048\n",
      "Iteration 28, loss = 0.75218877\n",
      "Iteration 29, loss = 0.75170372\n",
      "Iteration 30, loss = 0.75035988\n",
      "Iteration 31, loss = 0.75033041\n",
      "Iteration 32, loss = 0.74947070\n",
      "Iteration 33, loss = 0.74850568\n",
      "Iteration 34, loss = 0.74825425\n",
      "Iteration 35, loss = 0.74733650\n",
      "Iteration 36, loss = 0.74697613\n",
      "Iteration 37, loss = 0.74628011\n",
      "Iteration 38, loss = 0.74583685\n",
      "Iteration 39, loss = 0.74486669\n",
      "Iteration 40, loss = 0.74486061\n",
      "Iteration 41, loss = 0.74416629\n",
      "Iteration 42, loss = 0.74337008\n",
      "Iteration 43, loss = 0.74345099\n",
      "Iteration 44, loss = 0.74264149\n",
      "Iteration 45, loss = 0.74184734\n",
      "Iteration 46, loss = 0.74191145\n",
      "Iteration 47, loss = 0.74118452\n",
      "Iteration 48, loss = 0.74106460\n",
      "Iteration 49, loss = 0.74018820\n",
      "Iteration 50, loss = 0.73986063\n",
      "Iteration 51, loss = 0.73935461\n",
      "Iteration 52, loss = 0.73917382\n",
      "Iteration 53, loss = 0.73854468\n",
      "Iteration 54, loss = 0.73766802\n",
      "Iteration 55, loss = 0.73850761\n",
      "Iteration 56, loss = 0.73716214\n",
      "Iteration 57, loss = 0.73679218\n",
      "Iteration 58, loss = 0.73649966\n",
      "Iteration 59, loss = 0.73628719\n",
      "Iteration 60, loss = 0.73617575\n",
      "Iteration 61, loss = 0.73646419\n",
      "Iteration 62, loss = 0.73530271\n",
      "Iteration 63, loss = 0.73494903\n",
      "Iteration 64, loss = 0.73430044\n",
      "Iteration 65, loss = 0.73382795\n",
      "Iteration 66, loss = 0.73426127\n",
      "Iteration 67, loss = 0.73359336\n",
      "Iteration 68, loss = 0.73301360\n",
      "Iteration 69, loss = 0.73276786\n",
      "Iteration 70, loss = 0.73314796\n",
      "Iteration 71, loss = 0.73237356\n",
      "Iteration 72, loss = 0.73264201\n",
      "Iteration 73, loss = 0.73140332\n",
      "Iteration 74, loss = 0.73138270\n",
      "Iteration 75, loss = 0.73134973\n",
      "Iteration 76, loss = 0.73069586\n",
      "Iteration 77, loss = 0.73071374\n",
      "Iteration 78, loss = 0.73055754\n",
      "Iteration 79, loss = 0.73015012\n",
      "Iteration 80, loss = 0.72966215\n",
      "Iteration 81, loss = 0.72949614\n",
      "Iteration 82, loss = 0.72924444\n",
      "Iteration 83, loss = 0.72947067\n",
      "Iteration 84, loss = 0.72916219\n",
      "Iteration 85, loss = 0.72858857\n",
      "Iteration 86, loss = 0.72878725\n",
      "Iteration 87, loss = 0.72812741\n",
      "Iteration 88, loss = 0.72784992\n",
      "Iteration 89, loss = 0.72786886\n",
      "Iteration 90, loss = 0.72747963\n",
      "Iteration 91, loss = 0.72727076\n",
      "Iteration 92, loss = 0.72697017\n",
      "Iteration 93, loss = 0.72657028\n",
      "Iteration 94, loss = 0.72682830\n",
      "Iteration 95, loss = 0.72663614\n",
      "Iteration 96, loss = 0.72617484\n",
      "Iteration 97, loss = 0.72621497\n",
      "Iteration 98, loss = 0.72587462\n",
      "Iteration 99, loss = 0.72578215\n",
      "Iteration 100, loss = 0.72550782\n",
      "Iteration 101, loss = 0.72548922\n",
      "Iteration 102, loss = 0.72468660\n",
      "Iteration 103, loss = 0.72474973\n",
      "Iteration 104, loss = 0.72480889\n",
      "Iteration 105, loss = 0.72494404\n",
      "Iteration 106, loss = 0.72478027\n",
      "Iteration 107, loss = 0.72436492\n",
      "Iteration 108, loss = 0.72449374\n",
      "Iteration 109, loss = 0.72391512\n",
      "Iteration 110, loss = 0.72389424\n",
      "Iteration 111, loss = 0.72339291\n",
      "Iteration 112, loss = 0.72310209\n",
      "Iteration 113, loss = 0.72350384\n",
      "Iteration 114, loss = 0.72353016\n",
      "Iteration 115, loss = 0.72287295\n",
      "Iteration 116, loss = 0.72260173\n",
      "Iteration 117, loss = 0.72247923\n",
      "Iteration 118, loss = 0.72269838\n",
      "Iteration 119, loss = 0.72261037\n",
      "Iteration 120, loss = 0.72182914\n",
      "Iteration 121, loss = 0.72167297\n",
      "Iteration 122, loss = 0.72215268\n",
      "Iteration 123, loss = 0.72177728\n",
      "Iteration 124, loss = 0.72167165\n",
      "Iteration 125, loss = 0.72154902\n",
      "Iteration 126, loss = 0.72149300\n",
      "Iteration 127, loss = 0.72131071\n",
      "Iteration 128, loss = 0.72100300\n",
      "Iteration 129, loss = 0.72109971\n",
      "Iteration 130, loss = 0.72164037\n",
      "Iteration 131, loss = 0.72067331\n",
      "Iteration 132, loss = 0.72085315\n",
      "Iteration 133, loss = 0.72101411\n",
      "Iteration 134, loss = 0.72047704\n",
      "Iteration 135, loss = 0.72034467\n",
      "Iteration 136, loss = 0.72025776\n",
      "Iteration 137, loss = 0.72017247\n",
      "Iteration 138, loss = 0.72032402\n",
      "Iteration 139, loss = 0.71984080\n",
      "Iteration 140, loss = 0.71987887\n",
      "Iteration 141, loss = 0.72007611\n",
      "Iteration 142, loss = 0.71936934\n",
      "Iteration 143, loss = 0.71955780\n",
      "Iteration 144, loss = 0.71981211\n",
      "Iteration 145, loss = 0.71948329\n",
      "Iteration 146, loss = 0.71969428\n",
      "Iteration 147, loss = 0.71853005\n",
      "Iteration 148, loss = 0.71836979\n",
      "Iteration 149, loss = 0.71889895\n",
      "Iteration 150, loss = 0.71884958\n",
      "Iteration 151, loss = 0.71859061\n",
      "Iteration 152, loss = 0.71878398\n",
      "Iteration 153, loss = 0.71827645\n",
      "Iteration 154, loss = 0.71811337\n",
      "Iteration 155, loss = 0.71804529\n",
      "Iteration 156, loss = 0.71808917\n",
      "Iteration 157, loss = 0.71755942\n",
      "Iteration 158, loss = 0.71754451\n",
      "Iteration 159, loss = 0.71787235\n",
      "Iteration 160, loss = 0.71719196\n",
      "Iteration 161, loss = 0.71696768\n",
      "Iteration 162, loss = 0.71728699\n",
      "Iteration 163, loss = 0.71711334\n",
      "Iteration 164, loss = 0.71774587\n",
      "Iteration 165, loss = 0.71722019\n",
      "Iteration 166, loss = 0.71658790\n",
      "Iteration 167, loss = 0.71704409\n",
      "Iteration 168, loss = 0.71657341\n",
      "Iteration 169, loss = 0.71610582\n",
      "Iteration 170, loss = 0.71638081\n",
      "Iteration 171, loss = 0.71700458\n",
      "Iteration 172, loss = 0.71614254\n",
      "Iteration 173, loss = 0.71615093\n",
      "Iteration 174, loss = 0.71589837\n",
      "Iteration 175, loss = 0.71621342\n",
      "Iteration 176, loss = 0.71561247\n",
      "Iteration 177, loss = 0.71578200\n",
      "Iteration 178, loss = 0.71547635\n",
      "Iteration 179, loss = 0.71581857\n",
      "Iteration 180, loss = 0.71574566\n",
      "Iteration 181, loss = 0.71615760\n",
      "Iteration 182, loss = 0.71472876\n",
      "Iteration 183, loss = 0.71523045\n",
      "Iteration 184, loss = 0.71485696\n",
      "Iteration 185, loss = 0.71508056\n",
      "Iteration 186, loss = 0.71436493\n",
      "Iteration 187, loss = 0.71475624\n",
      "Iteration 188, loss = 0.71410674\n",
      "Iteration 189, loss = 0.71515366\n",
      "Iteration 190, loss = 0.71402467\n",
      "Iteration 191, loss = 0.71479960\n",
      "Iteration 192, loss = 0.71421111\n",
      "Iteration 193, loss = 0.71428123\n",
      "Iteration 194, loss = 0.71429038\n",
      "Iteration 195, loss = 0.71328589\n",
      "Iteration 196, loss = 0.71341689\n",
      "Iteration 197, loss = 0.71345946\n",
      "Iteration 198, loss = 0.71324699\n",
      "Iteration 199, loss = 0.71364312\n",
      "Iteration 200, loss = 0.71341811\n",
      "Iteration 201, loss = 0.71349305\n",
      "Iteration 202, loss = 0.71339280\n",
      "Iteration 203, loss = 0.71335121\n",
      "Iteration 204, loss = 0.71289746\n",
      "Iteration 205, loss = 0.71318773\n",
      "Iteration 206, loss = 0.71320966\n",
      "Iteration 207, loss = 0.71276853\n",
      "Iteration 208, loss = 0.71259081\n",
      "Iteration 209, loss = 0.71262962\n",
      "Iteration 210, loss = 0.71252800\n",
      "Iteration 211, loss = 0.71244178\n",
      "Iteration 212, loss = 0.71243321\n",
      "Iteration 213, loss = 0.71247053\n",
      "Iteration 214, loss = 0.71203446\n",
      "Iteration 215, loss = 0.71265544\n",
      "Iteration 216, loss = 0.71169417\n",
      "Iteration 217, loss = 0.71183742\n",
      "Iteration 218, loss = 0.71161625\n",
      "Iteration 219, loss = 0.71231758\n",
      "Iteration 220, loss = 0.71135524\n",
      "Iteration 221, loss = 0.71146064\n",
      "Iteration 222, loss = 0.71147568\n",
      "Iteration 223, loss = 0.71204818\n",
      "Iteration 224, loss = 0.71103188\n",
      "Iteration 225, loss = 0.71114181\n",
      "Iteration 226, loss = 0.71054908\n",
      "Iteration 227, loss = 0.71124621\n",
      "Iteration 228, loss = 0.71032151\n",
      "Iteration 229, loss = 0.71021217\n",
      "Iteration 230, loss = 0.71068975\n",
      "Iteration 231, loss = 0.71080732\n",
      "Iteration 232, loss = 0.71035543\n",
      "Iteration 233, loss = 0.71049762\n",
      "Iteration 234, loss = 0.71055315\n",
      "Iteration 235, loss = 0.71017008\n",
      "Iteration 236, loss = 0.71002222\n",
      "Iteration 237, loss = 0.71003963\n",
      "Iteration 238, loss = 0.70983551\n",
      "Iteration 239, loss = 0.70927763\n",
      "Iteration 240, loss = 0.70956661\n",
      "Iteration 241, loss = 0.70909917\n",
      "Iteration 242, loss = 0.71003108\n",
      "Iteration 243, loss = 0.70930909\n",
      "Iteration 244, loss = 0.70950922\n",
      "Iteration 245, loss = 0.70923083\n",
      "Iteration 246, loss = 0.70880546\n",
      "Iteration 247, loss = 0.70919342\n",
      "Iteration 248, loss = 0.70846104\n",
      "Iteration 249, loss = 0.70882839\n",
      "Iteration 250, loss = 0.70862611\n",
      "Iteration 251, loss = 0.70879957\n",
      "Iteration 252, loss = 0.70938547\n",
      "Iteration 253, loss = 0.70823087\n",
      "Iteration 254, loss = 0.70822729\n",
      "Iteration 255, loss = 0.70830484\n",
      "Iteration 256, loss = 0.70802181\n",
      "Iteration 257, loss = 0.70802326\n",
      "Iteration 258, loss = 0.70806153\n",
      "Iteration 259, loss = 0.70767149\n",
      "Iteration 260, loss = 0.70740887\n",
      "Iteration 261, loss = 0.70724652\n",
      "Iteration 262, loss = 0.70753653\n",
      "Iteration 263, loss = 0.70744032\n",
      "Iteration 264, loss = 0.70737721\n",
      "Iteration 265, loss = 0.70745312\n",
      "Iteration 266, loss = 0.70767725\n",
      "Iteration 267, loss = 0.70703906\n",
      "Iteration 268, loss = 0.70716889\n",
      "Iteration 269, loss = 0.70685210\n",
      "Iteration 270, loss = 0.70773946\n",
      "Iteration 271, loss = 0.70663493\n",
      "Iteration 272, loss = 0.70636308\n",
      "Iteration 273, loss = 0.70621975\n",
      "Iteration 274, loss = 0.70630249\n",
      "Iteration 275, loss = 0.70654364\n",
      "Iteration 276, loss = 0.70677552\n",
      "Iteration 277, loss = 0.70635231\n",
      "Iteration 278, loss = 0.70613387\n",
      "Iteration 279, loss = 0.70649132\n",
      "Iteration 280, loss = 0.70599536\n",
      "Iteration 281, loss = 0.70532057\n",
      "Iteration 282, loss = 0.70562190\n",
      "Iteration 283, loss = 0.70561970\n",
      "Iteration 284, loss = 0.70548750\n",
      "Iteration 285, loss = 0.70451109\n",
      "Iteration 286, loss = 0.70534603\n",
      "Iteration 287, loss = 0.70507466\n",
      "Iteration 288, loss = 0.70491628\n",
      "Iteration 289, loss = 0.70512069\n",
      "Iteration 290, loss = 0.70472970\n",
      "Iteration 291, loss = 0.70560369\n",
      "Iteration 292, loss = 0.70564956\n",
      "Iteration 293, loss = 0.70464145\n",
      "Iteration 294, loss = 0.70464342\n",
      "Iteration 295, loss = 0.70506457\n",
      "Iteration 296, loss = 0.70421139\n",
      "Iteration 297, loss = 0.70474688\n",
      "Iteration 298, loss = 0.70486837\n",
      "Iteration 299, loss = 0.70379504\n",
      "Iteration 300, loss = 0.70427368\n",
      "Iteration 301, loss = 0.70400056\n",
      "Iteration 302, loss = 0.70352665\n",
      "Iteration 303, loss = 0.70403428\n",
      "Iteration 304, loss = 0.70362207\n",
      "Iteration 305, loss = 0.70292086\n",
      "Iteration 306, loss = 0.70309563\n",
      "Iteration 307, loss = 0.70392009\n",
      "Iteration 308, loss = 0.70229056\n",
      "Iteration 309, loss = 0.70390084\n",
      "Iteration 310, loss = 0.70318072\n",
      "Iteration 311, loss = 0.70295886\n",
      "Iteration 312, loss = 0.70321630\n",
      "Iteration 313, loss = 0.70274512\n",
      "Iteration 314, loss = 0.70325750\n",
      "Iteration 315, loss = 0.70284007\n",
      "Iteration 316, loss = 0.70339655\n",
      "Iteration 317, loss = 0.70244458\n",
      "Iteration 318, loss = 0.70276309\n",
      "Iteration 319, loss = 0.70250087\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6395058647367108"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MLPClassifier(max_iter=2000, verbose=2, activation='relu', alpha=0.05, hidden_layer_sizes=(119,119,62), learning_rate='constant', solver='sgd', learning_rate_init=0.001)\n",
    "regr.fit(X_train_norm, y_train)\n",
    "regr.score(X_test_norm, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "0.39072754266319415"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, regr.predict(X_test_norm), average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy is 63.9%, F1 macro is 39.1%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}